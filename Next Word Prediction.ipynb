{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a340c76f",
   "metadata": {},
   "source": [
    "# Next Word Prediction - NLP - RNN/LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a0abd",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5264b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Embedding, LSTM\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb8b63",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7ee58ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The First Line:  One morning, when Gregor Samsa woke from troubled dreams, he found\n",
      "\n",
      "The Last Line:  first to get up and stretch out her young body.\n"
     ]
    }
   ],
   "source": [
    "path = 'gutenberg.txt'\n",
    "\n",
    "file = open(path,\"r\",encoding='utf-8')\n",
    "lines = []\n",
    "\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "    \n",
    "print(\"The First Line: \", lines[0])\n",
    "print(\"The Last Line: \", lines[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408b0b9a",
   "metadata": {},
   "source": [
    "### Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75d508b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin.  He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections.  The bedding was hardly able to cover it and seemed ready to slide off any moment.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"\"\n",
    "\n",
    "for i in lines:\n",
    "    data = ' '. join(lines)\n",
    "    \n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
    "data[:360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97174f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One morning  when Gregor Samsa woke from troubled dreams  he found himself transformed in his bed into a horrible vermin   He lay on his armour like back  and if he lifted his head a little he could see his brown belly  slightly domed and divided by arches into stiff sections   The bedding was hardly able to cover it and seemed ready to slide off any moment   His many legs  pitifully thin compared with the size of the rest of him  waved about helplessly as he looked    What s happened to me   he'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) #map punctuation to space\n",
    "new_data = data.translate(translator)\n",
    "\n",
    "new_data[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53c6b1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin. He lay on armour-like back, and if lifted head little could see brown belly, slightly domed divided by arches stiff sections. The bedding was hardly able to cover it seemed ready slide off any moment. His many legs, pitifully thin compared with the size of rest him, waved about helplessly as looked. \"What\\'s happened me?\" thought. It wasn\\'t dream. room, proper human room altho'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = []\n",
    "\n",
    "for i in data.split():\n",
    "    if i not in z:\n",
    "        z.append(i)\n",
    "        \n",
    "data = ' '.join(z)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ec6dd",
   "metadata": {},
   "source": [
    "### Keras Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d50b2978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 53, 293, 2, 18, 729, 135, 730, 294, 8]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "# saving the tokenizer for predict function.\n",
    "pickle.dump(tokenizer, open('tokenizer1.pkl', 'wb'))\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "sequence_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cdca2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2617\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "376b6794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Length of sequences are:  3889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 17,  53],\n",
       "       [ 53, 293],\n",
       "       [293,   2],\n",
       "       [  2,  18],\n",
       "       [ 18, 729],\n",
       "       [729, 135],\n",
       "       [135, 730],\n",
       "       [730, 294],\n",
       "       [294,   8],\n",
       "       [  8, 731]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = []\n",
    "\n",
    "for i in range(1, len(sequence_data)):\n",
    "    words = sequence_data[i-1:i+1]\n",
    "    sequences.append(words)\n",
    "    \n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)    #Convert to Numpy Matrix\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7db3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sequences:\n",
    "    X.append(i[0])\n",
    "    y.append(i[1])\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0140098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Data is:  [ 17  53 293   2  18]\n",
      "The responses are:  [ 53 293   2  18 729]\n"
     ]
    }
   ],
   "source": [
    "print(\"The Data is: \", X[:5])\n",
    "print(\"The responses are: \", y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "223ddb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1447ff",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4139694",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=1))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "928d6738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1, 10)             26170     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2617)              2619617   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,694,787\n",
      "Trainable params: 15,694,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eb1ab5",
   "metadata": {},
   "source": [
    "### Plot The Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28bd06eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"nextword1.h5\", monitor='loss', verbose=1,\n",
    "    save_best_only=True, mode='auto')\n",
    "\n",
    "reduce = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001, verbose = 1)\n",
    "\n",
    "logdir='logsnextword1'\n",
    "tensorboard_Visualization = TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404341ee",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a94b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "980e6556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 4.2823 - accuracy: 0.0774\n",
      "Epoch 1: loss did not improve from 4.00048\n",
      "58/58 [==============================] - 24s 232ms/step - loss: 4.2823 - accuracy: 0.0774 - val_loss: 4.8981 - val_accuracy: 0.0462 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.5853 - accuracy: 0.1345\n",
      "Epoch 2: loss improved from 4.00048 to 3.58534, saving model to nextword1.h5\n",
      "58/58 [==============================] - 12s 211ms/step - loss: 3.5853 - accuracy: 0.1345 - val_loss: 6.0190 - val_accuracy: 0.0667 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.3678 - accuracy: 0.1416\n",
      "Epoch 3: loss improved from 3.58534 to 3.36784, saving model to nextword1.h5\n",
      "58/58 [==============================] - 12s 203ms/step - loss: 3.3678 - accuracy: 0.1416 - val_loss: 6.6100 - val_accuracy: 0.0513 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.2843 - accuracy: 0.1348\n",
      "Epoch 4: loss improved from 3.36784 to 3.28432, saving model to nextword1.h5\n",
      "58/58 [==============================] - 15s 254ms/step - loss: 3.2843 - accuracy: 0.1348 - val_loss: 7.1018 - val_accuracy: 0.0513 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.1933 - accuracy: 0.1486\n",
      "Epoch 5: loss improved from 3.28432 to 3.19334, saving model to nextword1.h5\n",
      "58/58 [==============================] - 13s 218ms/step - loss: 3.1933 - accuracy: 0.1486 - val_loss: 7.4010 - val_accuracy: 0.0462 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 3.0747 - accuracy: 0.1681\n",
      "Epoch 6: loss improved from 3.19334 to 3.07472, saving model to nextword1.h5\n",
      "58/58 [==============================] - 12s 210ms/step - loss: 3.0747 - accuracy: 0.1681 - val_loss: 7.6435 - val_accuracy: 0.0615 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.9780 - accuracy: 0.1857\n",
      "Epoch 7: loss improved from 3.07472 to 2.97800, saving model to nextword1.h5\n",
      "58/58 [==============================] - 12s 205ms/step - loss: 2.9780 - accuracy: 0.1857 - val_loss: 7.9837 - val_accuracy: 0.0462 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.9029 - accuracy: 0.1819\n",
      "Epoch 8: loss improved from 2.97800 to 2.90289, saving model to nextword1.h5\n",
      "58/58 [==============================] - 11s 195ms/step - loss: 2.9029 - accuracy: 0.1819 - val_loss: 8.4131 - val_accuracy: 0.0615 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.8100 - accuracy: 0.2030\n",
      "Epoch 9: loss improved from 2.90289 to 2.80998, saving model to nextword1.h5\n",
      "58/58 [==============================] - 11s 188ms/step - loss: 2.8100 - accuracy: 0.2030 - val_loss: 8.6312 - val_accuracy: 0.0462 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.7723 - accuracy: 0.2049\n",
      "Epoch 10: loss improved from 2.80998 to 2.77234, saving model to nextword1.h5\n",
      "58/58 [==============================] - 13s 227ms/step - loss: 2.7723 - accuracy: 0.2049 - val_loss: 8.9180 - val_accuracy: 0.0205 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.7287 - accuracy: 0.2122\n",
      "Epoch 11: loss improved from 2.77234 to 2.72871, saving model to nextword1.h5\n",
      "58/58 [==============================] - 14s 234ms/step - loss: 2.7287 - accuracy: 0.2122 - val_loss: 8.9935 - val_accuracy: 0.0308 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.6535 - accuracy: 0.2193\n",
      "Epoch 12: loss improved from 2.72871 to 2.65354, saving model to nextword1.h5\n",
      "58/58 [==============================] - 11s 186ms/step - loss: 2.6535 - accuracy: 0.2193 - val_loss: 9.1471 - val_accuracy: 0.0513 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.5679 - accuracy: 0.2371\n",
      "Epoch 13: loss improved from 2.65354 to 2.56786, saving model to nextword1.h5\n",
      "58/58 [==============================] - 12s 200ms/step - loss: 2.5679 - accuracy: 0.2371 - val_loss: 9.4650 - val_accuracy: 0.0513 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.5025 - accuracy: 0.2469\n",
      "Epoch 14: loss improved from 2.56786 to 2.50247, saving model to nextword1.h5\n",
      "58/58 [==============================] - 11s 187ms/step - loss: 2.5025 - accuracy: 0.2469 - val_loss: 9.6861 - val_accuracy: 0.0051 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.4515 - accuracy: 0.2534\n",
      "Epoch 15: loss improved from 2.50247 to 2.45152, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 154ms/step - loss: 2.4515 - accuracy: 0.2534 - val_loss: 9.9296 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.4062 - accuracy: 0.2704\n",
      "Epoch 16: loss improved from 2.45152 to 2.40619, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 152ms/step - loss: 2.4062 - accuracy: 0.2704 - val_loss: 10.0014 - val_accuracy: 0.0462 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.3660 - accuracy: 0.2780\n",
      "Epoch 17: loss improved from 2.40619 to 2.36600, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 160ms/step - loss: 2.3660 - accuracy: 0.2780 - val_loss: 10.3323 - val_accuracy: 0.0410 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.3276 - accuracy: 0.2932\n",
      "Epoch 18: loss improved from 2.36600 to 2.32761, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 144ms/step - loss: 2.3276 - accuracy: 0.2932 - val_loss: 10.6267 - val_accuracy: 0.0205 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.3272 - accuracy: 0.2775\n",
      "Epoch 19: loss improved from 2.32761 to 2.32717, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 158ms/step - loss: 2.3272 - accuracy: 0.2775 - val_loss: 10.5368 - val_accuracy: 0.0462 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.2496 - accuracy: 0.2991\n",
      "Epoch 20: loss improved from 2.32717 to 2.24963, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 146ms/step - loss: 2.2496 - accuracy: 0.2991 - val_loss: 10.7905 - val_accuracy: 0.0462 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.2185 - accuracy: 0.2953\n",
      "Epoch 21: loss improved from 2.24963 to 2.21853, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 144ms/step - loss: 2.2185 - accuracy: 0.2953 - val_loss: 10.8793 - val_accuracy: 0.0308 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.1734 - accuracy: 0.3200\n",
      "Epoch 22: loss improved from 2.21853 to 2.17340, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 147ms/step - loss: 2.1734 - accuracy: 0.3200 - val_loss: 11.1221 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.1275 - accuracy: 0.3167\n",
      "Epoch 23: loss improved from 2.17340 to 2.12748, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 181ms/step - loss: 2.1275 - accuracy: 0.3167 - val_loss: 11.2824 - val_accuracy: 0.0205 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.1361 - accuracy: 0.3170\n",
      "Epoch 24: loss did not improve from 2.12748\n",
      "58/58 [==============================] - 7s 126ms/step - loss: 2.1361 - accuracy: 0.3170 - val_loss: 11.5205 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.0895 - accuracy: 0.3297\n",
      "Epoch 25: loss improved from 2.12748 to 2.08951, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 143ms/step - loss: 2.0895 - accuracy: 0.3297 - val_loss: 11.5878 - val_accuracy: 0.0205 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.0296 - accuracy: 0.3389\n",
      "Epoch 26: loss improved from 2.08951 to 2.02964, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 171ms/step - loss: 2.0296 - accuracy: 0.3389 - val_loss: 11.9414 - val_accuracy: 0.0154 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 2.0141 - accuracy: 0.3457\n",
      "Epoch 27: loss improved from 2.02964 to 2.01413, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 144ms/step - loss: 2.0141 - accuracy: 0.3457 - val_loss: 11.8898 - val_accuracy: 0.0154 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.9744 - accuracy: 0.3565\n",
      "Epoch 28: loss improved from 2.01413 to 1.97444, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 166ms/step - loss: 1.9744 - accuracy: 0.3565 - val_loss: 12.2929 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.9676 - accuracy: 0.3584\n",
      "Epoch 29: loss improved from 1.97444 to 1.96757, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 144ms/step - loss: 1.9676 - accuracy: 0.3584 - val_loss: 12.1808 - val_accuracy: 0.0154 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.9291 - accuracy: 0.3692\n",
      "Epoch 30: loss improved from 1.96757 to 1.92905, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 166ms/step - loss: 1.9291 - accuracy: 0.3692 - val_loss: 12.5754 - val_accuracy: 0.0103 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.9476 - accuracy: 0.3573\n",
      "Epoch 31: loss did not improve from 1.92905\n",
      "58/58 [==============================] - 8s 134ms/step - loss: 1.9476 - accuracy: 0.3573 - val_loss: 12.5637 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 32/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.9180 - accuracy: 0.3679\n",
      "Epoch 32: loss improved from 1.92905 to 1.91801, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 171ms/step - loss: 1.9180 - accuracy: 0.3679 - val_loss: 12.6322 - val_accuracy: 0.0308 - lr: 0.0010\n",
      "Epoch 33/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.8645 - accuracy: 0.3730\n",
      "Epoch 33: loss improved from 1.91801 to 1.86454, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 167ms/step - loss: 1.8645 - accuracy: 0.3730 - val_loss: 12.8328 - val_accuracy: 0.0205 - lr: 0.0010\n",
      "Epoch 34/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.8471 - accuracy: 0.3828\n",
      "Epoch 34: loss improved from 1.86454 to 1.84709, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 171ms/step - loss: 1.8471 - accuracy: 0.3828 - val_loss: 13.0772 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 35/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.8640 - accuracy: 0.3868\n",
      "Epoch 35: loss did not improve from 1.84709\n",
      "58/58 [==============================] - 8s 130ms/step - loss: 1.8640 - accuracy: 0.3868 - val_loss: 12.9352 - val_accuracy: 0.0205 - lr: 0.0010\n",
      "Epoch 36/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.8409 - accuracy: 0.3787\n",
      "Epoch 36: loss improved from 1.84709 to 1.84092, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 138ms/step - loss: 1.8409 - accuracy: 0.3787 - val_loss: 13.2607 - val_accuracy: 0.0154 - lr: 0.0010\n",
      "Epoch 37/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7712 - accuracy: 0.3950\n",
      "Epoch 37: loss improved from 1.84092 to 1.77119, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 145ms/step - loss: 1.7712 - accuracy: 0.3950 - val_loss: 13.2942 - val_accuracy: 0.0154 - lr: 0.0010\n",
      "Epoch 38/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7276 - accuracy: 0.4150\n",
      "Epoch 38: loss improved from 1.77119 to 1.72765, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 157ms/step - loss: 1.7276 - accuracy: 0.4150 - val_loss: 13.5013 - val_accuracy: 0.0154 - lr: 0.0010\n",
      "Epoch 39/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7056 - accuracy: 0.4115\n",
      "Epoch 39: loss improved from 1.72765 to 1.70559, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 159ms/step - loss: 1.7056 - accuracy: 0.4115 - val_loss: 13.7395 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 40/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.7001 - accuracy: 0.4134\n",
      "Epoch 40: loss improved from 1.70559 to 1.70010, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 157ms/step - loss: 1.7001 - accuracy: 0.4134 - val_loss: 13.8555 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 41/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6992 - accuracy: 0.4223\n",
      "Epoch 41: loss improved from 1.70010 to 1.69919, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 140ms/step - loss: 1.6992 - accuracy: 0.4223 - val_loss: 13.8522 - val_accuracy: 0.0103 - lr: 0.0010\n",
      "Epoch 42/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6866 - accuracy: 0.4247\n",
      "Epoch 42: loss improved from 1.69919 to 1.68662, saving model to nextword1.h5\n",
      "58/58 [==============================] - 11s 195ms/step - loss: 1.6866 - accuracy: 0.4247 - val_loss: 14.0971 - val_accuracy: 0.0103 - lr: 0.0010\n",
      "Epoch 43/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6497 - accuracy: 0.4239\n",
      "Epoch 43: loss improved from 1.68662 to 1.64974, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 149ms/step - loss: 1.6497 - accuracy: 0.4239 - val_loss: 14.1986 - val_accuracy: 0.0154 - lr: 0.0010\n",
      "Epoch 44/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6340 - accuracy: 0.4339\n",
      "Epoch 44: loss improved from 1.64974 to 1.63395, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 153ms/step - loss: 1.6340 - accuracy: 0.4339 - val_loss: 14.3107 - val_accuracy: 0.0103 - lr: 0.0010\n",
      "Epoch 45/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6283 - accuracy: 0.4296\n",
      "Epoch 45: loss improved from 1.63395 to 1.62834, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 149ms/step - loss: 1.6283 - accuracy: 0.4296 - val_loss: 14.3733 - val_accuracy: 0.0154 - lr: 0.0010\n",
      "Epoch 46/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6382 - accuracy: 0.4256\n",
      "Epoch 46: loss did not improve from 1.62834\n",
      "58/58 [==============================] - 9s 156ms/step - loss: 1.6382 - accuracy: 0.4256 - val_loss: 14.4887 - val_accuracy: 0.0103 - lr: 0.0010\n",
      "Epoch 47/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.6037 - accuracy: 0.4315\n",
      "Epoch 47: loss improved from 1.62834 to 1.60368, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 143ms/step - loss: 1.6037 - accuracy: 0.4315 - val_loss: 14.5732 - val_accuracy: 0.0103 - lr: 0.0010\n",
      "Epoch 48/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5929 - accuracy: 0.4402\n",
      "Epoch 48: loss improved from 1.60368 to 1.59294, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 153ms/step - loss: 1.5929 - accuracy: 0.4402 - val_loss: 14.6748 - val_accuracy: 0.0103 - lr: 0.0010\n",
      "Epoch 49/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5786 - accuracy: 0.4396\n",
      "Epoch 49: loss improved from 1.59294 to 1.57859, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 148ms/step - loss: 1.5786 - accuracy: 0.4396 - val_loss: 14.8188 - val_accuracy: 0.0256 - lr: 0.0010\n",
      "Epoch 50/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5439 - accuracy: 0.4545\n",
      "Epoch 50: loss improved from 1.57859 to 1.54389, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 159ms/step - loss: 1.5439 - accuracy: 0.4545 - val_loss: 15.1692 - val_accuracy: 0.0103 - lr: 0.0010\n",
      "Epoch 51/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5598 - accuracy: 0.4453\n",
      "Epoch 51: loss did not improve from 1.54389\n",
      "58/58 [==============================] - 8s 143ms/step - loss: 1.5598 - accuracy: 0.4453 - val_loss: 15.2408 - val_accuracy: 0.0205 - lr: 0.0010\n",
      "Epoch 52/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.5449 - accuracy: 0.4383\n",
      "Epoch 52: loss did not improve from 1.54389\n",
      "58/58 [==============================] - 7s 128ms/step - loss: 1.5449 - accuracy: 0.4383 - val_loss: 15.0600 - val_accuracy: 0.0103 - lr: 0.0010\n",
      "Epoch 53/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - ETA: 0s - loss: 1.5442 - accuracy: 0.4450\n",
      "Epoch 53: loss did not improve from 1.54389\n",
      "\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "58/58 [==============================] - 7s 128ms/step - loss: 1.5442 - accuracy: 0.4450 - val_loss: 15.2553 - val_accuracy: 0.0103 - lr: 0.0010\n",
      "Epoch 54/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 1.1490 - accuracy: 0.5604\n",
      "Epoch 54: loss improved from 1.54389 to 1.14900, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 170ms/step - loss: 1.1490 - accuracy: 0.5604 - val_loss: 15.5441 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 55/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.9962 - accuracy: 0.6021\n",
      "Epoch 55: loss improved from 1.14900 to 0.99622, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 159ms/step - loss: 0.9962 - accuracy: 0.6021 - val_loss: 15.7721 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 56/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.9382 - accuracy: 0.6007\n",
      "Epoch 56: loss improved from 0.99622 to 0.93823, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 144ms/step - loss: 0.9382 - accuracy: 0.6007 - val_loss: 16.1645 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 57/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.9092 - accuracy: 0.6048\n",
      "Epoch 57: loss improved from 0.93823 to 0.90921, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 153ms/step - loss: 0.9092 - accuracy: 0.6048 - val_loss: 16.4293 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 58/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8891 - accuracy: 0.5983\n",
      "Epoch 58: loss improved from 0.90921 to 0.88909, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 151ms/step - loss: 0.8891 - accuracy: 0.5983 - val_loss: 16.7483 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 59/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8740 - accuracy: 0.6040\n",
      "Epoch 59: loss improved from 0.88909 to 0.87400, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 165ms/step - loss: 0.8740 - accuracy: 0.6040 - val_loss: 17.0545 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 60/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8623 - accuracy: 0.5939\n",
      "Epoch 60: loss improved from 0.87400 to 0.86232, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 148ms/step - loss: 0.8623 - accuracy: 0.5939 - val_loss: 17.3578 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 61/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8537 - accuracy: 0.5994\n",
      "Epoch 61: loss improved from 0.86232 to 0.85374, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 168ms/step - loss: 0.8537 - accuracy: 0.5994 - val_loss: 17.6137 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 62/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8480 - accuracy: 0.5904\n",
      "Epoch 62: loss improved from 0.85374 to 0.84803, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 142ms/step - loss: 0.8480 - accuracy: 0.5904 - val_loss: 17.8328 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 63/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8426 - accuracy: 0.5953\n",
      "Epoch 63: loss improved from 0.84803 to 0.84257, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 162ms/step - loss: 0.8426 - accuracy: 0.5953 - val_loss: 18.0625 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 64/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8370 - accuracy: 0.5926\n",
      "Epoch 64: loss improved from 0.84257 to 0.83699, saving model to nextword1.h5\n",
      "58/58 [==============================] - 12s 213ms/step - loss: 0.8370 - accuracy: 0.5926 - val_loss: 18.2388 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 65/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8327 - accuracy: 0.5899\n",
      "Epoch 65: loss improved from 0.83699 to 0.83272, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 176ms/step - loss: 0.8327 - accuracy: 0.5899 - val_loss: 18.5116 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 66/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8261 - accuracy: 0.5923\n",
      "Epoch 66: loss improved from 0.83272 to 0.82606, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 168ms/step - loss: 0.8261 - accuracy: 0.5923 - val_loss: 18.7186 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 67/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8248 - accuracy: 0.5926\n",
      "Epoch 67: loss improved from 0.82606 to 0.82483, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 160ms/step - loss: 0.8248 - accuracy: 0.5926 - val_loss: 18.9638 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 68/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8227 - accuracy: 0.5912\n",
      "Epoch 68: loss improved from 0.82483 to 0.82275, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 155ms/step - loss: 0.8227 - accuracy: 0.5912 - val_loss: 19.0797 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 69/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8165 - accuracy: 0.5893\n",
      "Epoch 69: loss improved from 0.82275 to 0.81645, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 142ms/step - loss: 0.8165 - accuracy: 0.5893 - val_loss: 19.2476 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 70/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8121 - accuracy: 0.5842\n",
      "Epoch 70: loss improved from 0.81645 to 0.81208, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 143ms/step - loss: 0.8121 - accuracy: 0.5842 - val_loss: 19.5356 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 71/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8101 - accuracy: 0.5915\n",
      "Epoch 71: loss improved from 0.81208 to 0.81009, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 147ms/step - loss: 0.8101 - accuracy: 0.5915 - val_loss: 19.6518 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 72/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8081 - accuracy: 0.5975\n",
      "Epoch 72: loss improved from 0.81009 to 0.80813, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 143ms/step - loss: 0.8081 - accuracy: 0.5975 - val_loss: 19.7408 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 73/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8031 - accuracy: 0.5880\n",
      "Epoch 73: loss improved from 0.80813 to 0.80315, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 149ms/step - loss: 0.8031 - accuracy: 0.5880 - val_loss: 19.9079 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 74/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8012 - accuracy: 0.5926\n",
      "Epoch 74: loss improved from 0.80315 to 0.80122, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 156ms/step - loss: 0.8012 - accuracy: 0.5926 - val_loss: 20.0724 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 75/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.8003 - accuracy: 0.5807\n",
      "Epoch 75: loss improved from 0.80122 to 0.80033, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 139ms/step - loss: 0.8003 - accuracy: 0.5807 - val_loss: 20.3246 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 76/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7994 - accuracy: 0.5864\n",
      "Epoch 76: loss improved from 0.80033 to 0.79938, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 139ms/step - loss: 0.7994 - accuracy: 0.5864 - val_loss: 20.4463 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 77/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7962 - accuracy: 0.5847\n",
      "Epoch 77: loss improved from 0.79938 to 0.79620, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 163ms/step - loss: 0.7962 - accuracy: 0.5847 - val_loss: 20.5202 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - ETA: 0s - loss: 0.7903 - accuracy: 0.5891\n",
      "Epoch 78: loss improved from 0.79620 to 0.79029, saving model to nextword1.h5\n",
      "58/58 [==============================] - 12s 206ms/step - loss: 0.7903 - accuracy: 0.5891 - val_loss: 20.6545 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 79/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7955 - accuracy: 0.5899\n",
      "Epoch 79: loss did not improve from 0.79029\n",
      "58/58 [==============================] - 8s 134ms/step - loss: 0.7955 - accuracy: 0.5899 - val_loss: 20.6878 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 80/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7867 - accuracy: 0.5823\n",
      "Epoch 80: loss improved from 0.79029 to 0.78673, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 170ms/step - loss: 0.7867 - accuracy: 0.5823 - val_loss: 20.8044 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 81/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7886 - accuracy: 0.5964\n",
      "Epoch 81: loss did not improve from 0.78673\n",
      "58/58 [==============================] - 7s 129ms/step - loss: 0.7886 - accuracy: 0.5964 - val_loss: 21.0630 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 82/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7836 - accuracy: 0.5915\n",
      "Epoch 82: loss improved from 0.78673 to 0.78358, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 173ms/step - loss: 0.7836 - accuracy: 0.5915 - val_loss: 21.0606 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 83/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7823 - accuracy: 0.5869\n",
      "Epoch 83: loss improved from 0.78358 to 0.78234, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 147ms/step - loss: 0.7823 - accuracy: 0.5869 - val_loss: 21.2489 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 84/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7798 - accuracy: 0.5831\n",
      "Epoch 84: loss improved from 0.78234 to 0.77981, saving model to nextword1.h5\n",
      "58/58 [==============================] - 13s 219ms/step - loss: 0.7798 - accuracy: 0.5831 - val_loss: 21.3871 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 85/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7795 - accuracy: 0.5845\n",
      "Epoch 85: loss improved from 0.77981 to 0.77951, saving model to nextword1.h5\n",
      "58/58 [==============================] - 12s 203ms/step - loss: 0.7795 - accuracy: 0.5845 - val_loss: 21.5689 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 86/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7791 - accuracy: 0.5858\n",
      "Epoch 86: loss improved from 0.77951 to 0.77905, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 172ms/step - loss: 0.7791 - accuracy: 0.5858 - val_loss: 21.6264 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 87/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7752 - accuracy: 0.5864\n",
      "Epoch 87: loss improved from 0.77905 to 0.77519, saving model to nextword1.h5\n",
      "58/58 [==============================] - 11s 186ms/step - loss: 0.7752 - accuracy: 0.5864 - val_loss: 21.6979 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 88/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7728 - accuracy: 0.5861\n",
      "Epoch 88: loss improved from 0.77519 to 0.77282, saving model to nextword1.h5\n",
      "58/58 [==============================] - 11s 189ms/step - loss: 0.7728 - accuracy: 0.5861 - val_loss: 21.8440 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 89/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7721 - accuracy: 0.5801\n",
      "Epoch 89: loss improved from 0.77282 to 0.77213, saving model to nextword1.h5\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 0.7721 - accuracy: 0.5801 - val_loss: 21.9110 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 90/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7713 - accuracy: 0.5818\n",
      "Epoch 90: loss improved from 0.77213 to 0.77127, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 153ms/step - loss: 0.7713 - accuracy: 0.5818 - val_loss: 22.0336 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 91/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7663 - accuracy: 0.5861\n",
      "Epoch 91: loss improved from 0.77127 to 0.76629, saving model to nextword1.h5\n",
      "58/58 [==============================] - 12s 201ms/step - loss: 0.7663 - accuracy: 0.5861 - val_loss: 22.0489 - val_accuracy: 0.0103 - lr: 2.0000e-04\n",
      "Epoch 92/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7700 - accuracy: 0.5861\n",
      "Epoch 92: loss did not improve from 0.76629\n",
      "58/58 [==============================] - 9s 148ms/step - loss: 0.7700 - accuracy: 0.5861 - val_loss: 22.1975 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 93/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7694 - accuracy: 0.5818\n",
      "Epoch 93: loss did not improve from 0.76629\n",
      "58/58 [==============================] - 9s 159ms/step - loss: 0.7694 - accuracy: 0.5818 - val_loss: 22.1993 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 94/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7645 - accuracy: 0.5872\n",
      "Epoch 94: loss improved from 0.76629 to 0.76446, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 148ms/step - loss: 0.7645 - accuracy: 0.5872 - val_loss: 22.3858 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 95/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7662 - accuracy: 0.5866\n",
      "Epoch 95: loss did not improve from 0.76446\n",
      "58/58 [==============================] - 7s 123ms/step - loss: 0.7662 - accuracy: 0.5866 - val_loss: 22.2173 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 96/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7614 - accuracy: 0.5850\n",
      "Epoch 96: loss improved from 0.76446 to 0.76143, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 153ms/step - loss: 0.7614 - accuracy: 0.5850 - val_loss: 22.5185 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 97/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7598 - accuracy: 0.5820\n",
      "Epoch 97: loss improved from 0.76143 to 0.75975, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 141ms/step - loss: 0.7598 - accuracy: 0.5820 - val_loss: 22.5755 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 98/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7595 - accuracy: 0.5845\n",
      "Epoch 98: loss improved from 0.75975 to 0.75946, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 148ms/step - loss: 0.7595 - accuracy: 0.5845 - val_loss: 22.5550 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 99/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7589 - accuracy: 0.5812\n",
      "Epoch 99: loss improved from 0.75946 to 0.75889, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 142ms/step - loss: 0.7589 - accuracy: 0.5812 - val_loss: 22.6094 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 100/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7569 - accuracy: 0.5831\n",
      "Epoch 100: loss improved from 0.75889 to 0.75690, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 164ms/step - loss: 0.7569 - accuracy: 0.5831 - val_loss: 22.7762 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 101/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7542 - accuracy: 0.5861\n",
      "Epoch 101: loss improved from 0.75690 to 0.75418, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 148ms/step - loss: 0.7542 - accuracy: 0.5861 - val_loss: 22.7202 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 102/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7559 - accuracy: 0.5888\n",
      "Epoch 102: loss did not improve from 0.75418\n",
      "58/58 [==============================] - 8s 135ms/step - loss: 0.7559 - accuracy: 0.5888 - val_loss: 22.9246 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 103/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7518 - accuracy: 0.5855\n",
      "Epoch 103: loss improved from 0.75418 to 0.75184, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 159ms/step - loss: 0.7518 - accuracy: 0.5855 - val_loss: 22.8092 - val_accuracy: 0.0051 - lr: 2.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7508 - accuracy: 0.5831\n",
      "Epoch 104: loss improved from 0.75184 to 0.75076, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 170ms/step - loss: 0.7508 - accuracy: 0.5831 - val_loss: 22.9908 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 105/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7525 - accuracy: 0.5826\n",
      "Epoch 105: loss did not improve from 0.75076\n",
      "58/58 [==============================] - 8s 146ms/step - loss: 0.7525 - accuracy: 0.5826 - val_loss: 22.9774 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 106/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7486 - accuracy: 0.5877\n",
      "Epoch 106: loss improved from 0.75076 to 0.74861, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 141ms/step - loss: 0.7486 - accuracy: 0.5877 - val_loss: 23.0055 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 107/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7472 - accuracy: 0.5942\n",
      "Epoch 107: loss improved from 0.74861 to 0.74724, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 163ms/step - loss: 0.7472 - accuracy: 0.5942 - val_loss: 23.1184 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 108/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7505 - accuracy: 0.5818\n",
      "Epoch 108: loss did not improve from 0.74724\n",
      "58/58 [==============================] - 7s 129ms/step - loss: 0.7505 - accuracy: 0.5818 - val_loss: 23.2026 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 109/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7465 - accuracy: 0.5853\n",
      "Epoch 109: loss improved from 0.74724 to 0.74646, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 139ms/step - loss: 0.7465 - accuracy: 0.5853 - val_loss: 23.2268 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 110/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7453 - accuracy: 0.5823\n",
      "Epoch 110: loss improved from 0.74646 to 0.74529, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 153ms/step - loss: 0.7453 - accuracy: 0.5823 - val_loss: 23.4392 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 111/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7466 - accuracy: 0.5853\n",
      "Epoch 111: loss did not improve from 0.74529\n",
      "58/58 [==============================] - 8s 131ms/step - loss: 0.7466 - accuracy: 0.5853 - val_loss: 23.2993 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 112/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7442 - accuracy: 0.5891\n",
      "Epoch 112: loss improved from 0.74529 to 0.74422, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 163ms/step - loss: 0.7442 - accuracy: 0.5891 - val_loss: 23.3134 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 113/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7458 - accuracy: 0.5891\n",
      "Epoch 113: loss did not improve from 0.74422\n",
      "58/58 [==============================] - 8s 132ms/step - loss: 0.7458 - accuracy: 0.5891 - val_loss: 23.4741 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 114/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7438 - accuracy: 0.5818\n",
      "Epoch 114: loss improved from 0.74422 to 0.74378, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 151ms/step - loss: 0.7438 - accuracy: 0.5818 - val_loss: 23.4973 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 115/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7389 - accuracy: 0.5872\n",
      "Epoch 115: loss improved from 0.74378 to 0.73892, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 161ms/step - loss: 0.7389 - accuracy: 0.5872 - val_loss: 23.4441 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 116/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7408 - accuracy: 0.5790\n",
      "Epoch 116: loss did not improve from 0.73892\n",
      "58/58 [==============================] - 7s 125ms/step - loss: 0.7408 - accuracy: 0.5790 - val_loss: 23.4596 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 117/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7418 - accuracy: 0.5864\n",
      "Epoch 117: loss did not improve from 0.73892\n",
      "58/58 [==============================] - 7s 126ms/step - loss: 0.7418 - accuracy: 0.5864 - val_loss: 23.6650 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 118/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7370 - accuracy: 0.5866\n",
      "Epoch 118: loss improved from 0.73892 to 0.73705, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 152ms/step - loss: 0.7370 - accuracy: 0.5866 - val_loss: 23.6811 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 119/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7391 - accuracy: 0.5815\n",
      "Epoch 119: loss did not improve from 0.73705\n",
      "58/58 [==============================] - 8s 144ms/step - loss: 0.7391 - accuracy: 0.5815 - val_loss: 23.6900 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 120/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7396 - accuracy: 0.5839\n",
      "Epoch 120: loss did not improve from 0.73705\n",
      "58/58 [==============================] - 9s 150ms/step - loss: 0.7396 - accuracy: 0.5839 - val_loss: 23.6690 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 121/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7357 - accuracy: 0.5861\n",
      "Epoch 121: loss improved from 0.73705 to 0.73573, saving model to nextword1.h5\n",
      "58/58 [==============================] - 11s 187ms/step - loss: 0.7357 - accuracy: 0.5861 - val_loss: 23.7138 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 122/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7371 - accuracy: 0.5818\n",
      "Epoch 122: loss did not improve from 0.73573\n",
      "58/58 [==============================] - 7s 127ms/step - loss: 0.7371 - accuracy: 0.5818 - val_loss: 23.8549 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 123/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7407 - accuracy: 0.5858\n",
      "Epoch 123: loss did not improve from 0.73573\n",
      "58/58 [==============================] - 7s 124ms/step - loss: 0.7407 - accuracy: 0.5858 - val_loss: 23.9978 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 124/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7346 - accuracy: 0.5904\n",
      "Epoch 124: loss improved from 0.73573 to 0.73464, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 142ms/step - loss: 0.7346 - accuracy: 0.5904 - val_loss: 23.9067 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 125/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7373 - accuracy: 0.5910\n",
      "Epoch 125: loss did not improve from 0.73464\n",
      "58/58 [==============================] - 8s 134ms/step - loss: 0.7373 - accuracy: 0.5910 - val_loss: 23.9729 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 126/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7324 - accuracy: 0.5883\n",
      "Epoch 126: loss improved from 0.73464 to 0.73242, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 161ms/step - loss: 0.7324 - accuracy: 0.5883 - val_loss: 23.9041 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 127/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7323 - accuracy: 0.5801\n",
      "Epoch 127: loss improved from 0.73242 to 0.73231, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 169ms/step - loss: 0.7323 - accuracy: 0.5801 - val_loss: 23.9724 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 128/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7335 - accuracy: 0.5842\n",
      "Epoch 128: loss did not improve from 0.73231\n",
      "58/58 [==============================] - 8s 144ms/step - loss: 0.7335 - accuracy: 0.5842 - val_loss: 24.1975 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 129/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7303 - accuracy: 0.5812\n",
      "Epoch 129: loss improved from 0.73231 to 0.73028, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 152ms/step - loss: 0.7303 - accuracy: 0.5812 - val_loss: 23.9967 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 130/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7288 - accuracy: 0.5872\n",
      "Epoch 130: loss improved from 0.73028 to 0.72882, saving model to nextword1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 8s 146ms/step - loss: 0.7288 - accuracy: 0.5872 - val_loss: 24.0481 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 131/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7268 - accuracy: 0.5858\n",
      "Epoch 131: loss improved from 0.72882 to 0.72678, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 166ms/step - loss: 0.7268 - accuracy: 0.5858 - val_loss: 24.2237 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 132/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7299 - accuracy: 0.5809\n",
      "Epoch 132: loss did not improve from 0.72678\n",
      "58/58 [==============================] - 8s 135ms/step - loss: 0.7299 - accuracy: 0.5809 - val_loss: 24.0743 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 133/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7246 - accuracy: 0.5831\n",
      "Epoch 133: loss improved from 0.72678 to 0.72457, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 153ms/step - loss: 0.7246 - accuracy: 0.5831 - val_loss: 24.2784 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 134/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7275 - accuracy: 0.5820\n",
      "Epoch 134: loss did not improve from 0.72457\n",
      "58/58 [==============================] - 7s 126ms/step - loss: 0.7275 - accuracy: 0.5820 - val_loss: 24.1830 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 135/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7238 - accuracy: 0.5850\n",
      "Epoch 135: loss improved from 0.72457 to 0.72378, saving model to nextword1.h5\n",
      "58/58 [==============================] - 8s 142ms/step - loss: 0.7238 - accuracy: 0.5850 - val_loss: 24.0634 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 136/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7280 - accuracy: 0.5836\n",
      "Epoch 136: loss did not improve from 0.72378\n",
      "58/58 [==============================] - 8s 139ms/step - loss: 0.7280 - accuracy: 0.5836 - val_loss: 24.2137 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 137/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7240 - accuracy: 0.5847\n",
      "Epoch 137: loss did not improve from 0.72378\n",
      "58/58 [==============================] - 8s 138ms/step - loss: 0.7240 - accuracy: 0.5847 - val_loss: 24.3557 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 138/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.7252 - accuracy: 0.5872\n",
      "Epoch 138: loss did not improve from 0.72378\n",
      "\n",
      "Epoch 138: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "58/58 [==============================] - 9s 150ms/step - loss: 0.7252 - accuracy: 0.5872 - val_loss: 24.3479 - val_accuracy: 0.0051 - lr: 2.0000e-04\n",
      "Epoch 139/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6596 - accuracy: 0.5929\n",
      "Epoch 139: loss improved from 0.72378 to 0.65957, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 170ms/step - loss: 0.6596 - accuracy: 0.5929 - val_loss: 24.2789 - val_accuracy: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 140/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6560 - accuracy: 0.5877\n",
      "Epoch 140: loss improved from 0.65957 to 0.65601, saving model to nextword1.h5\n",
      "58/58 [==============================] - 11s 182ms/step - loss: 0.6560 - accuracy: 0.5877 - val_loss: 24.4039 - val_accuracy: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 141/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6547 - accuracy: 0.5885\n",
      "Epoch 141: loss improved from 0.65601 to 0.65467, saving model to nextword1.h5\n",
      "58/58 [==============================] - 11s 193ms/step - loss: 0.6547 - accuracy: 0.5885 - val_loss: 24.4461 - val_accuracy: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 142/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6544 - accuracy: 0.5842\n",
      "Epoch 142: loss improved from 0.65467 to 0.65439, saving model to nextword1.h5\n",
      "58/58 [==============================] - 13s 225ms/step - loss: 0.6544 - accuracy: 0.5842 - val_loss: 24.4823 - val_accuracy: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 143/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6514 - accuracy: 0.5850\n",
      "Epoch 143: loss improved from 0.65439 to 0.65137, saving model to nextword1.h5\n",
      "58/58 [==============================] - 10s 171ms/step - loss: 0.6514 - accuracy: 0.5850 - val_loss: 24.5102 - val_accuracy: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 144/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6530 - accuracy: 0.5780\n",
      "Epoch 144: loss did not improve from 0.65137\n",
      "58/58 [==============================] - 9s 148ms/step - loss: 0.6530 - accuracy: 0.5780 - val_loss: 24.6463 - val_accuracy: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 145/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6531 - accuracy: 0.5855\n",
      "Epoch 145: loss did not improve from 0.65137\n",
      "58/58 [==============================] - 7s 127ms/step - loss: 0.6531 - accuracy: 0.5855 - val_loss: 24.7349 - val_accuracy: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 146/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6516 - accuracy: 0.5831\n",
      "Epoch 146: loss did not improve from 0.65137\n",
      "58/58 [==============================] - 8s 137ms/step - loss: 0.6516 - accuracy: 0.5831 - val_loss: 24.6823 - val_accuracy: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 147/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6509 - accuracy: 0.5826\n",
      "Epoch 147: loss improved from 0.65137 to 0.65092, saving model to nextword1.h5\n",
      "58/58 [==============================] - 9s 162ms/step - loss: 0.6509 - accuracy: 0.5826 - val_loss: 24.7005 - val_accuracy: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 148/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6523 - accuracy: 0.5809\n",
      "Epoch 148: loss did not improve from 0.65092\n",
      "58/58 [==============================] - 9s 159ms/step - loss: 0.6523 - accuracy: 0.5809 - val_loss: 24.8502 - val_accuracy: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 149/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6514 - accuracy: 0.5815\n",
      "Epoch 149: loss did not improve from 0.65092\n",
      "58/58 [==============================] - 8s 138ms/step - loss: 0.6514 - accuracy: 0.5815 - val_loss: 24.8371 - val_accuracy: 0.0051 - lr: 1.0000e-04\n",
      "Epoch 150/150\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.6514 - accuracy: 0.5785\n",
      "Epoch 150: loss did not improve from 0.65092\n",
      "58/58 [==============================] - 8s 141ms/step - loss: 0.6514 - accuracy: 0.5785 - val_loss: 24.8512 - val_accuracy: 0.0051 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=150,validation_split=0.05, batch_size=64,shuffle=True, callbacks=[checkpoint, reduce, tensorboard_Visualization]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f882c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(history, open(\"history.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f5fc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('nextword1.h5')\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "feefefed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec11a704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c2958d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
